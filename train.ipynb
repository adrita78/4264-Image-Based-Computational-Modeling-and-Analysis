{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","drive_dir = \"/content/drive/MyDrive/Computational Image Analysis and Modelling Project\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fd7IFnQwKH1V","executionInfo":{"status":"ok","timestamp":1670879376019,"user_tz":300,"elapsed":20115,"user":{"displayName":"Alonso Buitano Tang","userId":"02723529498790255492"}},"outputId":"02939483-763c-47a5-d783-f02b8a09feff"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!nvidia-smi -L"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XRMa91mpTrkV","executionInfo":{"status":"ok","timestamp":1670879376407,"user_tz":300,"elapsed":392,"user":{"displayName":"Alonso Buitano Tang","userId":"02723529498790255492"}},"outputId":"00c72c20-8018-4df9-c2a9-5dfddfcb9b0f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-b935eaaa-855f-1d19-0020-55f0248939fa)\n"]}]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/Computational Image Analysis and Modelling Project/GraphRegNet/utils.py\" ."],"metadata":{"id":"8hhIL4o5LYsn","executionInfo":{"status":"ok","timestamp":1670879378116,"user_tz":300,"elapsed":1711,"user":{"displayName":"Alonso Buitano Tang","userId":"02723529498790255492"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"7hQ3MOmAV7eK","executionInfo":{"status":"ok","timestamp":1670879380441,"user_tz":300,"elapsed":2331,"user":{"displayName":"Alonso Buitano Tang","userId":"02723529498790255492"}}},"outputs":[],"source":["# imports\n","\n","import nibabel as nib\n","import numpy as np\n","import os\n","import random\n","import time\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.checkpoint import checkpoint\n","from torch.autograd import Function\n","from torch.autograd.functional import jacobian as J\n","\n","from utils import *"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"gjoKXe0iV7eM","executionInfo":{"status":"ok","timestamp":1670879380441,"user_tz":300,"elapsed":7,"user":{"displayName":"Alonso Buitano Tang","userId":"02723529498790255492"}}},"outputs":[],"source":["# settings\n","\n","# data\n","cases = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n","fold = 0\n","if fold == 0:  \n","    test_cases = [0, 5, 10, 15, 20, 25]\n","elif fold == 1:\n","    test_cases = [1, 6, 11, 16, 21, 26]\n","elif fold == 2:\n","    test_cases = [2, 7, 12, 17, 22, 27]\n","elif fold == 3:\n","    test_cases = [3, 8, 13, 18, 23, 28]\n","elif fold == 4:\n","    test_cases = [4, 9, 14, 19, 24, 29]\n","train_cases = [i for i in cases if not i in test_cases]\n","\n","# misc\n","device = 'cuda'\n","torch.backends.cudnn.enabled = True\n","torch.backends.cudnn.benchmark = True\n","model_dir = 'fold{}'.format(fold)\n","if not os.path.exists(os.path.join(drive_dir+'/models/', model_dir)):\n","    os.makedirs(os.path.join(drive_dir+'/models/', model_dir))\n","data_dir = drive_dir+'/data/preprocessed/'\n","    \n","# keypoints / graph\n","d = 3 # 5 (for refinement stage)\n","N_P = 3072 # 2048 (for refinement stage)\n","k = 15\n","\n","# displacements\n","l_max = 8 # 14 (for refinement stage)\n","l_width = l_max * 2 + 1\n","q = 1 # 2 (for refinement stage)\n","\n","# model\n","base = 4\n","sigma2 = 1\n","\n","# training\n","num_epochs = 150\n","init_lr = 0.00000125\n","save_iter = 1"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5gHrY_9V7eN","executionInfo":{"status":"ok","timestamp":1670879463739,"user_tz":300,"elapsed":83304,"user":{"displayName":"Alonso Buitano Tang","userId":"02723529498790255492"}},"outputId":"1bba5371-9b69-47b6-ca02-aa1f6ef69ea4"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading case 2 ... 4.41 s\n","loading case 3 ... 2.97 s\n","loading case 4 ... 4.23 s\n","loading case 5 ... 2.71 s\n","loading case 7 ... 2.84 s\n","loading case 8 ... 3.32 s\n","loading case 9 ... 3.86 s\n","loading case 10 ... 2.80 s\n","loading case 12 ... 3.40 s\n","loading case 13 ... 3.53 s\n","loading case 14 ... 3.58 s\n","loading case 15 ... 3.27 s\n","loading case 17 ... 4.00 s\n","loading case 18 ... 2.89 s\n","loading case 19 ... 3.60 s\n","loading case 20 ... 4.26 s\n","loading case 22 ... 3.41 s\n","loading case 23 ... 3.75 s\n","loading case 24 ... 3.90 s\n","loading case 25 ... 3.55 s\n","loading case 27 ... 2.74 s\n","loading case 28 ... 3.45 s\n","loading case 29 ... 3.74 s\n","loading case 30 ... 3.30 s\n"]}],"source":["# load data\n","\n","imgs_fixed = {}\n","masks_fixed = {}\n","imgs_moving = {}\n","masks_moving = {}\n","\n","for case in train_cases:\n","    print('loading case {} ...'.format(case + 1), end=' ')\n","    \n","    t0 = time.time()\n","    input_img_fixed = os.path.join(data_dir, '{0:02d}_img_fixed.nii.gz'.format(case + 1))\n","    input_mask_fixed = os.path.join(data_dir, '{0:02d}_mask_fixed.nii.gz'.format(case + 1))\n","    input_img_moving = os.path.join(data_dir, '{0:02d}_img_moving.nii.gz'.format(case + 1))\n","    input_mask_moving = os.path.join(data_dir, '{0:02d}_mask_moving.nii.gz'.format(case + 1))\n","    \n","    img_fixed = (torch.from_numpy(nib.load(input_img_fixed).get_data()).unsqueeze(0).unsqueeze(0).float().clamp_(-1000, 1500) + 1000) / 2500\n","    mask_fixed = torch.from_numpy(nib.load(input_mask_fixed).get_data()).unsqueeze(0).unsqueeze(0).bool()\n","    img_moving = (torch.from_numpy(nib.load(input_img_moving).get_data()).unsqueeze(0).unsqueeze(0).float().clamp_(-1000, 1500) + 1000) / 2500\n","    mask_moving = torch.from_numpy(nib.load(input_mask_moving).get_data()).unsqueeze(0).unsqueeze(0).bool()\n","    \n","    imgs_fixed[case] = img_fixed\n","    masks_fixed[case] = mask_fixed\n","    imgs_moving[case] = img_moving\n","    masks_moving[case] = mask_moving\n","    t1 = time.time()\n","    \n","    print('{:.2f} s'.format(t1-t0))\n","\n","_, _, D, H, W = imgs_fixed[train_cases[0]].shape"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"OxunKr-2V7eN","executionInfo":{"status":"ok","timestamp":1670879468319,"user_tz":300,"elapsed":4598,"user":{"displayName":"Alonso Buitano Tang","userId":"02723529498790255492"}}},"outputs":[],"source":["# displacement space\n","\n","disp = torch.stack(torch.meshgrid(torch.arange(- q * l_max, q * l_max + 1, q * 2),\n","                                  torch.arange(- q * l_max, q * l_max + 1, q * 2),\n","                                  torch.arange(- q * l_max, q * l_max + 1, q * 2))).permute(1, 2, 3, 0).contiguous().view(1, -1, 3).float()\n","disp = (disp.flip(-1) * 2 / (torch.tensor([W, H, D]) - 1)).to(device)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"gQIkyv5DV7eO","executionInfo":{"status":"ok","timestamp":1670879468320,"user_tz":300,"elapsed":24,"user":{"displayName":"Alonso Buitano Tang","userId":"02723529498790255492"}}},"outputs":[],"source":["# graphregnet\n","\n","class GaussianSmoothing(nn.Module):\n","    def __init__(self, sigma):\n","        super(GaussianSmoothing, self).__init__()\n","        \n","        sigma = torch.tensor([sigma]).to(device)\n","        N = torch.ceil(sigma * 3.0 / 2.0).long().item() * 2 + 1\n","    \n","        weight = torch.exp(-torch.pow(torch.linspace(-(N // 2), N // 2, N).to(device), 2) / (2 * torch.pow(sigma, 2)))\n","        weight /= weight.sum()\n","        \n","        self.weight = weight\n","        \n","    def forward(self, x):\n","        \n","        x = filter1D(x, self.weight, 0)\n","        x = filter1D(x, self.weight, 1)\n","        x = filter1D(x, self.weight, 2)\n","        \n","        return x\n","\n","class Encoder(nn.Module):\n","    def __init__(self, in_channels=1, base=4):\n","        super(Encoder, self).__init__()\n","    \n","        self.conv_in = nn.Sequential(nn.Conv3d(in_channels, base, 3, stride=2, padding=1, bias=False),\n","                                     nn.InstanceNorm3d(base),\n","                                     nn.LeakyReLU())\n","        \n","        self.conv1 = nn.Sequential(nn.Conv3d(base, 2*base, 3, stride=2, padding=1, bias=False),\n","                                   nn.InstanceNorm3d(2*base),\n","                                   nn.LeakyReLU())\n","        \n","        self.conv2 = nn.Sequential(nn.Conv3d(2*base, 4*base, 3, stride=2, padding=1, bias=False),\n","                                   nn.InstanceNorm3d(4*base),\n","                                   nn.LeakyReLU())\n","        \n","    def forward(self, x):\n","        \n","        x1 = self.conv_in(x)\n","        x2 = self.conv1(x1)\n","        x3 = self.conv2(x2)\n","        \n","        return x1, x2, x3\n","            \n","class Decoder(nn.Module):\n","    def __init__(self, out_channels=1, base=4):\n","        super(Decoder, self).__init__()\n","        \n","        self.conv1 = nn.Sequential(nn.Conv3d(4*base, 2*base, 3, stride=1, padding=1, bias=False),\n","                                   nn.InstanceNorm3d(2*base),\n","                                   nn.LeakyReLU())\n","    \n","        self.conv1a = nn.Sequential(nn.Conv3d(4*base, 2*base, 3, stride=1, padding=1, bias=False),\n","                                    nn.InstanceNorm3d(2*base),\n","                                    nn.LeakyReLU())\n","        \n","        self.conv2 = nn.Sequential(nn.Conv3d(2*base, base, 3, stride=1, padding=1, bias=False),\n","                                   nn.InstanceNorm3d(base),\n","                                   nn.LeakyReLU())\n","        \n","        self.conv2a = nn.Sequential(nn.Conv3d(2*base, base, 3, stride=1, padding=1, bias=False),\n","                                    nn.InstanceNorm3d(base),\n","                                    nn.LeakyReLU())\n","        \n","        self.conv_out = nn.Sequential(nn.Conv3d(base, 1, 3, padding=1))\n","        \n","    def forward(self, x1, x2, x3):\n","        x = F.interpolate(x3, size=x2.shape[-3:], mode='trilinear')\n","        x = self.conv1(x)\n","        x = self.conv1a(torch.cat([x, x2], dim=1))\n","        x = F.interpolate(x, size=x1.shape[-3:], mode='trilinear')\n","        x = self.conv2(x)\n","        x = self.conv2a(torch.cat([x, x1], dim=1))\n","        x = self.conv_out(x)\n","        return x\n","    \n","class EdgeConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(EdgeConv, self).__init__()\n","        \n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","    \n","        self.conv = nn.Sequential(\n","            nn.Conv3d(self.in_channels * 2, self.out_channels, 1, bias=False),\n","            nn.InstanceNorm3d(self.out_channels),\n","            nn.LeakyReLU()\n","        )\n","        \n","    def forward(self, x, ind):\n","        B, N, C, D, _, _ = x.shape\n","        k = ind.shape[2]\n","        \n","        y = x.view(B*N, C, D*D*D)[ind.view(B*N, k)].view(B, N, k, C, D*D*D)\n","        x = x.view(B, N, C, D*D*D).unsqueeze(2).expand(-1, -1, k, -1, -1)\n","        \n","        x = torch.cat([y - x, x], dim=3).permute(0, 3, 1, 2, 4)\n","        \n","        x = self.conv(x)\n","    \n","        x = x.mean(dim=3).permute(0, 2, 1, 3).view(B, N, -1, D, D, D)\n","        return x\n","    \n","class GCN(nn.Module):\n","    def __init__(self, base=4):\n","        super(GCN, self).__init__()\n","        \n","        self.base = base\n","        \n","        self.conv1 = EdgeConv(4*self.base + 3, 4*self.base)\n","        self.conv2 = EdgeConv(2*4*self.base + 3, 4*self.base)\n","        self.conv3 = EdgeConv(3*4*self.base + 3, 4*self.base)\n","        \n","    def forward(self, x1, x2, x3, kpts, ind):\n","        expand = x3.shape[-1]\n","        xa = self.conv1(torch.cat([x3, kpts.view(-1, 3, 1, 1, 1).expand(-1, -1, expand, expand, expand)], dim=1).unsqueeze(0), ind).squeeze(0)\n","        xb = self.conv2(torch.cat([torch.cat([x3, kpts.view(-1, 3, 1, 1, 1).expand(-1, -1, expand, expand, expand)], dim=1), xa], dim=1).unsqueeze(0), ind).squeeze(0)\n","        xc = self.conv3(torch.cat([torch.cat([x3, kpts.view(-1, 3, 1, 1, 1).expand(-1, -1, expand, expand, expand)], dim=1), xa, xb], dim=1).unsqueeze(0), ind).squeeze(0)\n","        return x1, x2, xc\n","    \n","class GraphRegNet(nn.Module):\n","    def __init__(self, base, smooth_sigma):\n","        super(GraphRegNet, self).__init__()\n","        \n","        self.base = base\n","        self.smooth_sigma = smooth_sigma\n","        \n","        self.pre_filter1 = GaussianSmoothing(self.smooth_sigma)\n","        self.pre_filter2 = GaussianSmoothing(self.smooth_sigma)\n","            \n","        self.encoder1 = Encoder(2, self.base)\n","        self.gcn1 = GCN(self.base)\n","        self.decoder1 = Decoder(1, self.base)\n","        \n","        self.encoder2 = Encoder(4, self.base)\n","        self.gcn2 = GCN(self.base)\n","        self.decoder2 = Decoder(1, self.base)\n","        \n","    def forward(self, x, kpts, kpts_knn):\n","        \n","        x1 = self.encoder1(torch.cat([x, self.pre_filter1(x)], dim=1))\n","            \n","        # x1 = checkpoint(self.gcn1, *x1, kpts, kpts_knn) \n","        x1 = self.gcn1(*x1, kpts, kpts_knn)\n","        x1 = self.decoder1(*x1)\n","        # x1 = checkpoint(self.decoder1, *x1)\n","        x1 = F.interpolate(x1, size=x.shape[-3:], mode='trilinear')\n","        \n","        x2 = self.encoder2(torch.cat([x, self.pre_filter1(x), x1, self.pre_filter2(x1)], dim=1))\n","                \n","        # x2 = checkpoint(self.gcn2, *x2, kpts, kpts_knn) \n","        x2 = self.gcn2(*x2, kpts, kpts_knn)\n","        x2 = self.decoder2(*x2)\n","        \n","        return x2\n","                           \n","def init_weights(m):\n","    if isinstance(m, nn.Conv3d):\n","        nn.init.xavier_normal(m.weight)\n","        if m.bias is not None:\n","            nn.init.constant(m.bias, 0.0)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"pT5a5V-uV7eP","executionInfo":{"status":"ok","timestamp":1670879468321,"user_tz":300,"elapsed":23,"user":{"displayName":"Alonso Buitano Tang","userId":"02723529498790255492"}}},"outputs":[],"source":["# differentiable sparse-to-dense supervision\n","\n","class InverseGridSample(Function):\n","    \n","    @staticmethod\n","    def forward(ctx, input, grid, shape, mode='bilinear', padding_mode='zeros', align_corners=None):\n","        B, C, N = input.shape\n","        D = grid.shape[-1]\n","        device = input.device\n","        dtype = input.dtype\n","        \n","        ctx.save_for_backward(input, grid)\n","        \n","        if D == 2:\n","            input_view = [B, C, -1, 1]\n","            grid_view = [B, -1, 1, 2]\n","        elif D == 3:\n","            input_view = [B, C, -1, 1, 1]\n","            grid_view = [B, -1, 1, 1, 3]\n","            \n","        ctx.grid_view = grid_view\n","        ctx.mode = mode\n","        ctx.padding_mode = padding_mode\n","        ctx.align_corners = align_corners\n","\n","        with torch.enable_grad():\n","            output = J(lambda x: InverseGridSample.sample(input.view(*input_view), grid.view(*grid_view), x, mode, padding_mode, align_corners), (torch.zeros(B, C, *shape).to(dtype).to(device)))\n","\n","        return output\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):        \n","        input, grid = ctx.saved_tensors\n","        grid_view = ctx.grid_view\n","        mode = ctx.mode\n","        padding_mode = ctx.padding_mode\n","        align_corners = ctx.align_corners\n","        \n","        grad_input = F.grid_sample(grad_output, grid.view(*grid_view), mode, padding_mode, align_corners)\n","        \n","        return grad_input.view(*input.shape), None, None, None, None, None\n","        \n","    @staticmethod\n","    def sample(input, grid, accu, mode='bilinear', padding_mode='zeros', align_corners=None):\n","        sampled = F.grid_sample(accu, grid, mode, padding_mode, align_corners)\n","        return -0.5 * ((input - sampled) ** 2).sum()\n","    \n","def inverse_grid_sample(input, grid, shape, mode='bilinear', padding_mode='zeros', align_corners=None):\n","    return InverseGridSample.apply(input, grid, shape, mode, padding_mode, align_corners)\n","\n","def densify(kpts, kpts_disp, shape, smooth_iter=3, kernel_size=5, eps=0.0001):\n","    B, N, _ = kpts.shape\n","    device = kpts.device\n","    D, H, W = shape\n","    \n","    grid = inverse_grid_sample(kpts_disp.permute(0, 2, 1), kpts, shape, padding_mode='border', align_corners=True)\n","    grid_norm = inverse_grid_sample(torch.ones(B, 1, N).to(device), kpts, shape, padding_mode='border', align_corners=True)\n","    \n","    avg_pool = nn.AvgPool3d(kernel_size, stride=1, padding=kernel_size // 2).to(device)\n","    for i in range(smooth_iter):\n","        grid = avg_pool(grid)\n","        grid_norm = avg_pool(grid_norm)\n","        \n","    grid = grid / (grid_norm + eps)\n","    \n","    return grid"]},{"cell_type":"code","execution_count":10,"metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"id":"2NOA46khV7eP","outputId":"c4f43d8a-6e34-4e24-edde-0ca7627392ac","executionInfo":{"status":"ok","timestamp":1670886590814,"user_tz":300,"elapsed":7122516,"user":{"displayName":"Alonso Buitano Tang","userId":"02723529498790255492"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["# parameters: 33506\n","epoch:  1\n","loss: 0.0475\n","time (epoch): 53.6281 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  2\n","loss: 0.0442\n","time (epoch): 45.1235 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  3\n","loss: 0.0416\n","time (epoch): 45.9127 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  4\n","loss: 0.0395\n","time (epoch): 45.7356 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  5\n","loss: 0.0379\n","time (epoch): 46.3455 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  6\n","loss: 0.0367\n","time (epoch): 46.0491 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  7\n","loss: 0.0357\n","time (epoch): 46.1924 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  8\n","loss: 0.0350\n","time (epoch): 46.2332 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  9\n","loss: 0.0344\n","time (epoch): 46.3922 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  10\n","loss: 0.0339\n","time (epoch): 46.4133 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  11\n","loss: 0.0335\n","time (epoch): 46.7243 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  12\n","loss: 0.0331\n","time (epoch): 46.2827 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  13\n","loss: 0.0328\n","time (epoch): 46.4691 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  14\n","loss: 0.0325\n","time (epoch): 46.3102 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  15\n","loss: 0.0322\n","time (epoch): 46.4113 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  16\n","loss: 0.0319\n","time (epoch): 46.7800 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  17\n","loss: 0.0316\n","time (epoch): 46.8864 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  18\n","loss: 0.0314\n","time (epoch): 46.3955 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  19\n","loss: 0.0311\n","time (epoch): 46.4070 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  20\n","loss: 0.0308\n","time (epoch): 46.4393 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  21\n","loss: 0.0306\n","time (epoch): 46.3997 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  22\n","loss: 0.0303\n","time (epoch): 46.4743 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  23\n","loss: 0.0301\n","time (epoch): 47.4123 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  24\n","loss: 0.0298\n","time (epoch): 46.8584 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  25\n","loss: 0.0295\n","time (epoch): 46.7896 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  26\n","loss: 0.0293\n","time (epoch): 46.8081 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  27\n","loss: 0.0290\n","time (epoch): 46.8329 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  28\n","loss: 0.0288\n","time (epoch): 46.7604 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  29\n","loss: 0.0285\n","time (epoch): 47.4720 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  30\n","loss: 0.0283\n","time (epoch): 46.8604 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  31\n","loss: 0.0280\n","time (epoch): 46.8259 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  32\n","loss: 0.0278\n","time (epoch): 46.8219 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  33\n","loss: 0.0275\n","time (epoch): 46.8574 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  34\n","loss: 0.0272\n","time (epoch): 46.8135 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  35\n","loss: 0.0270\n","time (epoch): 47.4726 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  36\n","loss: 0.0268\n","time (epoch): 46.8180 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  37\n","loss: 0.0265\n","time (epoch): 46.7928 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  38\n","loss: 0.0263\n","time (epoch): 46.8477 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  39\n","loss: 0.0260\n","time (epoch): 46.8105 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  40\n","loss: 0.0258\n","time (epoch): 46.8188 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  41\n","loss: 0.0255\n","time (epoch): 47.1340 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  42\n","loss: 0.0253\n","time (epoch): 46.8705 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  43\n","loss: 0.0251\n","time (epoch): 46.7796 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  44\n","loss: 0.0248\n","time (epoch): 46.8627 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  45\n","loss: 0.0246\n","time (epoch): 46.8781 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  46\n","loss: 0.0244\n","time (epoch): 47.1143 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  47\n","loss: 0.0242\n","time (epoch): 46.9962 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  48\n","loss: 0.0239\n","time (epoch): 46.8248 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  49\n","loss: 0.0237\n","time (epoch): 46.8506 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  50\n","loss: 0.0235\n","time (epoch): 46.7803 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  51\n","loss: 0.0233\n","time (epoch): 46.7394 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  52\n","loss: 0.0231\n","time (epoch): 47.1779 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  53\n","loss: 0.0229\n","time (epoch): 46.8330 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  54\n","loss: 0.0228\n","time (epoch): 46.8139 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  55\n","loss: 0.0226\n","time (epoch): 46.7232 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  56\n","loss: 0.0224\n","time (epoch): 46.7799 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  57\n","loss: 0.0223\n","time (epoch): 46.8199 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  58\n","loss: 0.0221\n","time (epoch): 47.2407 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  59\n","loss: 0.0219\n","time (epoch): 46.7424 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  60\n","loss: 0.0218\n","time (epoch): 46.8207 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  61\n","loss: 0.0217\n","time (epoch): 46.8077 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  62\n","loss: 0.0216\n","time (epoch): 46.7647 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  63\n","loss: 0.0215\n","time (epoch): 47.2634 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  64\n","loss: 0.0214\n","time (epoch): 46.8052 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  65\n","loss: 0.0213\n","time (epoch): 46.7914 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  66\n","loss: 0.0212\n","time (epoch): 46.8059 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  67\n","loss: 0.0211\n","time (epoch): 46.7708 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  68\n","loss: 0.0211\n","time (epoch): 46.7454 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  69\n","loss: 0.0210\n","time (epoch): 47.3214 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  70\n","loss: 0.0210\n","time (epoch): 46.8256 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  71\n","loss: 0.0210\n","time (epoch): 46.7583 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  72\n","loss: 0.0209\n","time (epoch): 46.7815 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  73\n","loss: 0.0210\n","time (epoch): 46.7322 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  74\n","loss: 0.0209\n","time (epoch): 46.8115 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  75\n","loss: 0.0210\n","time (epoch): 47.2666 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  76\n","loss: 0.0210\n","time (epoch): 46.8254 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  77\n","loss: 0.0210\n","time (epoch): 46.7729 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  78\n","loss: 0.0211\n","time (epoch): 46.7395 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  79\n","loss: 0.0211\n","time (epoch): 46.7454 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  80\n","loss: 0.0212\n","time (epoch): 47.0783 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  81\n","loss: 0.0212\n","time (epoch): 46.7602 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  82\n","loss: 0.0213\n","time (epoch): 46.7348 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  83\n","loss: 0.0214\n","time (epoch): 46.8121 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  84\n","loss: 0.0215\n","time (epoch): 46.6896 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  85\n","loss: 0.0216\n","time (epoch): 46.7759 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  86\n","loss: 0.0217\n","time (epoch): 47.2605 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  87\n","loss: 0.0218\n","time (epoch): 46.8397 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  88\n","loss: 0.0219\n","time (epoch): 46.8379 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  89\n","loss: 0.0221\n","time (epoch): 46.7690 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  90\n","loss: 0.0222\n","time (epoch): 46.7849 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  91\n","loss: 0.0223\n","time (epoch): 47.1382 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  92\n","loss: 0.0224\n","time (epoch): 46.7617 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  93\n","loss: 0.0226\n","time (epoch): 46.7261 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  94\n","loss: 0.0227\n","time (epoch): 46.7429 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  95\n","loss: 0.0228\n","time (epoch): 46.7395 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  96\n","loss: 0.0230\n","time (epoch): 46.7412 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  97\n","loss: 0.0232\n","time (epoch): 47.0476 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  98\n","loss: 0.0233\n","time (epoch): 46.6849 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  99\n","loss: 0.0234\n","time (epoch): 46.7763 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  100\n","loss: 0.0236\n","time (epoch): 46.7969 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  101\n","loss: 0.0237\n","time (epoch): 46.7747 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  102\n","loss: 0.0239\n","time (epoch): 47.2217 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  103\n","loss: 0.0240\n","time (epoch): 46.8046 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  104\n","loss: 0.0242\n","time (epoch): 46.7982 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  105\n","loss: 0.0244\n","time (epoch): 46.8507 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  106\n","loss: 0.0245\n","time (epoch): 46.8103 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  107\n","loss: 0.0246\n","time (epoch): 47.0084 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  108\n","loss: 0.0248\n","time (epoch): 47.2272 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  109\n","loss: 0.0249\n","time (epoch): 46.8182 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  110\n","loss: 0.0251\n","time (epoch): 46.8489 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  111\n","loss: 0.0253\n","time (epoch): 46.8279 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  112\n","loss: 0.0254\n","time (epoch): 46.8424 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  113\n","loss: 0.0256\n","time (epoch): 47.2663 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  114\n","loss: 0.0257\n","time (epoch): 46.7620 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  115\n","loss: 0.0259\n","time (epoch): 46.7333 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  116\n","loss: 0.0260\n","time (epoch): 46.7658 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  117\n","loss: 0.0262\n","time (epoch): 46.8821 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  118\n","loss: 0.0263\n","time (epoch): 47.3525 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  119\n","loss: 0.0265\n","time (epoch): 46.7875 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  120\n","loss: 0.0266\n","time (epoch): 46.7494 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  121\n","loss: 0.0268\n","time (epoch): 46.8095 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  122\n","loss: 0.0270\n","time (epoch): 46.7554 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  123\n","loss: 0.0271\n","time (epoch): 47.2235 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  124\n","loss: 0.0272\n","time (epoch): 46.7353 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  125\n","loss: 0.0274\n","time (epoch): 46.7220 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  126\n","loss: 0.0275\n","time (epoch): 46.8398 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  127\n","loss: 0.0277\n","time (epoch): 46.7507 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  128\n","loss: 0.0278\n","time (epoch): 46.7551 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  129\n","loss: 0.0280\n","time (epoch): 47.1931 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  130\n","loss: 0.0281\n","time (epoch): 46.7396 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  131\n","loss: 0.0283\n","time (epoch): 46.7504 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  132\n","loss: 0.0285\n","time (epoch): 46.8188 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  133\n","loss: 0.0286\n","time (epoch): 46.7155 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  134\n","loss: 0.0288\n","time (epoch): 47.3475 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  135\n","loss: 0.0289\n","time (epoch): 46.7441 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  136\n","loss: 0.0291\n","time (epoch): 46.7286 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  137\n","loss: 0.0293\n","time (epoch): 46.7136 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  138\n","loss: 0.0294\n","time (epoch): 46.6863 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  139\n","loss: 0.0296\n","time (epoch): 47.5090 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  140\n","loss: 0.0298\n","time (epoch): 46.7145 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  141\n","loss: 0.0299\n","time (epoch): 46.8776 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  142\n","loss: 0.0301\n","time (epoch): 46.7352 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  143\n","loss: 0.0303\n","time (epoch): 46.7639 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  144\n","loss: 0.0305\n","time (epoch): 47.1169 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  145\n","loss: 0.0307\n","time (epoch): 46.7936 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  146\n","loss: 0.0309\n","time (epoch): 46.7263 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  147\n","loss: 0.0310\n","time (epoch): 46.7485 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  148\n","loss: 0.0313\n","time (epoch): 46.8019 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  149\n","loss: 0.0314\n","time (epoch): 47.1346 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n","epoch:  150\n","loss: 0.0316\n","time (epoch): 46.8446 s\n","gpu usage (current/max): 0.77 / 7.79 GB\n","---\n"]}],"source":["# training\n","\n","# model\n","graphregnet = GraphRegNet(base, sigma2).to(device)\n","graphregnet.apply(init_weights)\n","parameter_count(graphregnet)\n","\n","# optimizer\n","optimizer = optim.Adam(graphregnet.parameters(), init_lr)\n","\n","# criterion\n","def criterion(feat_fixed, feat_moving, disp, mask):\n","    mse_loss = nn.MSELoss(reduction='none')\n","    loss = (mse_loss(feat_fixed, warp_img(feat_moving, disp.permute(0, 2, 3, 4, 1))) * mask).sum() / mask.float().sum()\n","    return loss\n","\n","# statistics\n","losses = []\n","torch.cuda.synchronize()\n","t0 = time.time()\n","\n","# for num_epochs epochs\n","for epoch in range(num_epochs):\n","    \n","    # train mode\n","    graphregnet.train()\n","    \n","    # statistics\n","    running_loss = 0.0\n","    \n","    # shuffle training cases\n","    train_cases_perm = random.sample(train_cases, len(train_cases))\n","    \n","    # for all training cases\n","    for case in train_cases_perm:\n","        \n","        # zero out gradients\n","        optimizer.zero_grad()\n","    \n","        # load data\n","        img_fixed = imgs_fixed[case].to(device)\n","        mask_fixed = masks_fixed[case].to(device)\n","        img_moving = imgs_moving[case].to(device)\n","        mask_moving = masks_moving[case].to(device)\n","\n","        # extract kpts and generate knn graph\n","        kpts_fixed = foerstner_kpts(img_fixed, mask_fixed, d=d, num_points=N_P)\n","        kpts_fixed_knn = knn_graph(kpts_fixed, k, include_self=True)[0]\n","        \n","        # extract mind features \n","        mind_fixed = mindssc(img_fixed)\n","        mind_moving = mindssc(img_moving)\n","\n","        # displacement cost computation\n","        cost = ssd(kpts_fixed, mind_fixed, mind_moving, (D, H, W), l_max, q).view(-1, 1, l_width, l_width, l_width)\n","        \n","        # forward\n","        kpts_fixed_disp_pred = graphregnet(cost, kpts_fixed, kpts_fixed_knn)\n","        \n","        # sparse to dense\n","        disp_pred = densify(kpts_fixed, (disp.unsqueeze(1) * F.softmax(kpts_fixed_disp_pred.view(1, N_P, -1), 2).unsqueeze(3)).sum(2), (D//3, H//3, W//3))\n","        disp_pred = F.interpolate(disp_pred, size=(D, H, W), mode='trilinear')\n","        \n","        # loss\n","        loss = criterion(mind_fixed, mind_moving, disp_pred, mask_moving)\n","        \n","        # backward + optimize\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # statistics\n","        running_loss += loss.item()\n","\n","    running_loss /= (len(train_cases))\n","    losses.append(running_loss)\n","        \n","    if ((epoch + 1) % save_iter) == 0:\n","    \n","        torch.cuda.synchronize()\n","        t1 = time.time()\n","        \n","        print('epoch: ', epoch + 1)\n","        print('loss: {:.4f}'.format(running_loss))\n","        print('time (epoch): {:.4f} s'.format((t1 - t0) / save_iter))\n","        gpu_usage()\n","        print('---')\n","        \n","        torch.save(graphregnet.cpu().state_dict(), os.path.join(drive_dir+'/models', model_dir, 'epoch{}.pth'.format(epoch)))\n","        graphregnet.to(device)\n","        \n","        torch.cuda.synchronize()\n","        t0 = time.time()\n","\n","# torch.save(graph_reg_net.cpu().state_dict(), os.path.join(drive_dir+'/models', model_dir, 'final.pth'))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}